defaults:
    - override hydra/launcher: submitit_local

dataset:
    _target_: mtm_research.datasets.exorl.get_datasets
    seq_steps: ???
    algorithm: ???
    env_name: walker_walk
    seed: 0
    replay_buffer_dir: "~/mtm/exorl_data"
    train_max_size: 1000000
    val_max_size: 10000
    num_workers: 16

model_config:
    _target_: mtm_research.models.mtm_model.MTMConfig
    norm: "none"
    n_embd: 512
    n_enc_layer: 2
    n_dec_layer: 1
    n_head: 4
    dropout: 0.1
    loss_keys: null
    latent_dim: null

state_only_dataset: null

args:
    _target_: pretrain_mtm.RunConfig
    seed: 0
    batch_size: 2048
    n_workers: 10
    traj_length: 4

    log_every: 100
    print_every: 1000
    eval_every: 20000
    save_every: 10000

    device: cuda
    mask_ratios: [0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 1.0]
    mask_patterns: ["AUTO_MASK"]
    warmup_steps: 40000
    num_train_steps: 140010
    learning_rate: 0.0001
    weight_decay:  0.005
    mode_weights: [0.2, 0.1, 0.7]
    tsp_ratio: 1


wandb:
  project: experiments
  entity: ""
  resume: null
  # resume: allow

job_name: job

hydra:
    job:
        name: mtm_mae