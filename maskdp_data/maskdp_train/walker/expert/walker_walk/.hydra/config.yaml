agent:
  _target_: agent.ddpg.DDPGAgent
  name: ddpg
  obs_type: ???
  obs_shape: ???
  action_shape: ???
  device: ${device}
  lr: 0.0001
  critic_target_tau: 0.01
  update_every_steps: 2
  use_tb: ${use_tb}
  use_wandb: ${use_wandb}
  num_expl_steps: ???
  hidden_dim: 1024
  feature_dim: 50
  stddev_schedule: 0.2
  stddev_clip: 0.3
  nstep: 3
  batch_size: 1024
  init_critic: true
  supervised: ${supervised}
  bonus: ${bonus}
domain: walker
obs_type: states
frame_stack: 1
action_repeat: 1
discount: 0.99
supervised: true
bonus: 0.5
task: walker_walk
num_train_frames: 2000010
num_seed_frames: 4000
eval_every_frames: 10000
num_eval_episodes: 10
save_snapshot: false
save_every_frames: 1000000
replay_buffer_size: 1000000
replay_buffer_num_workers: 4
save_replay_buffer: true
pre_trained_path: /shared/fangchen/rl_data_collection/exp_local/2022.05.03/063200_ddpg_walker_walk_0.5_states_1/snapshot_1000000.pt
batch_size: ${agent.batch_size}
nstep: ${agent.nstep}
update_encoder: true
seed: 1
device: cuda
save_video: true
save_train_video: false
use_tb: false
use_wandb: false
project: data_collection
entity: value_transformer
notes: exp
