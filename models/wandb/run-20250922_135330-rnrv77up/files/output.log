/home/dcc/miniconda3/envs/maskdp/lib/python3.8/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Error executing job with overrides: []
Traceback (most recent call last):
  File "pretest.py", line 120, in main
    metrics = agent.update(train_iter, global_step)
  File "/home/dcc/maskdp-taskgeneral/agent/mdp.py", line 262, in update
    batch = next(replay_iter)
  File "/home/dcc/miniconda3/envs/maskdp/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/dcc/miniconda3/envs/maskdp/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/dcc/miniconda3/envs/maskdp/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/dcc/miniconda3/envs/maskdp/lib/python3.8/site-packages/torch/_utils.py", line 722, in reraise
    raise exception
OSError: Caught OSError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/dcc/miniconda3/envs/maskdp/lib/python3.8/site-packages/numpy/lib/npyio.py", line 447, in load
    return pickle.load(fid, **pickle_kwargs)
_pickle.UnpicklingError: invalid load key, '<'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dcc/miniconda3/envs/maskdp/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/dcc/miniconda3/envs/maskdp/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 32, in fetch
    data.append(next(self.dataset_iter))
  File "/home/dcc/maskdp-taskgeneral/replay_buffer.py", line 182, in __iter__
    yield self._sample()
  File "/home/dcc/maskdp-taskgeneral/replay_buffer.py", line 120, in _sample
    episode = self._sample_episode()
  File "/home/dcc/maskdp-taskgeneral/replay_buffer.py", line 110, in _sample_episode
    self._load(self._relabel)
  File "/home/dcc/maskdp-taskgeneral/replay_buffer.py", line 101, in _load
    episode = load_episode(eps_fn, self._domain, self._obs)
  File "/home/dcc/maskdp-taskgeneral/replay_buffer.py", line 30, in load_episode
    episode = np.load(f, allow_pickle=True)
  File "/home/dcc/miniconda3/envs/maskdp/lib/python3.8/site-packages/numpy/lib/npyio.py", line 449, in load
    raise IOError(
OSError: Failed to interpret file <_io.BufferedReader name='../maskdp_data/maskdp_train/walker/expert/walker_walk/train/episode_000000_1000.npz'> as a pickle


Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
